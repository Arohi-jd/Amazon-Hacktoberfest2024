{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arohi-jd/Amazon-Hacktoberfest2024/blob/main/Swiggy_Case_Study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dfbe48a",
      "metadata": {
        "id": "5dfbe48a"
      },
      "source": [
        "# Decision Tree Regression - Delivery Time Prediction\n",
        "\n",
        "- Dataset URl - [Swiggy Data](https://www.kaggle.com/datasets/abhijitdahatonde/swiggy-restuarant-dataset)\n",
        "\n",
        "### Exercise: Build a Decision Tree Model\n",
        "\n",
        "In this exercise, you will build a Decision Tree Regressor to predict Swiggy delivery time. Fill in the blanks to complete the code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ac0c5c5",
      "metadata": {
        "id": "5ac0c5c5"
      },
      "source": [
        "* **Import Libraries:** This cell imports the necessary libraries for our model - `pandas` for data manipulation, and `sklearn` for machine learning.\n",
        "\n",
        "**Hints:**\n",
        "- Import `train_test_split` from sklearn's model_selection module\n",
        "- Import `DecisionTreeRegressor` from sklearn's tree module\n",
        "- Import evaluation metrics from sklearn's metrics module\n",
        "\n",
        "**Documentation:**\n",
        "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "- [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
        "- [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
        "- [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588459a4",
      "metadata": {
        "id": "588459a4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import ______  # Fill: function to split data\n",
        "from sklearn.tree import ______  # Fill: regressor class for decision trees\n",
        "from sklearn.metrics import mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d4a249b",
      "metadata": {
        "id": "2d4a249b"
      },
      "source": [
        "* **Load Dataset:** This cell loads the 'swiggy.csv' file and removes any rows with missing values.\n",
        "\n",
        "**Hints:**\n",
        "- Use `pd.read_csv()` to load CSV files\n",
        "- Use `.dropna()` to remove rows with missing values\n",
        "\n",
        "**Documentation:**\n",
        "- [pd.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
        "- [DataFrame.dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18c3de0",
      "metadata": {
        "id": "a18c3de0"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.______(______)  # Fill: method to read CSV, filename\n",
        "df = df.______()  # Fill: method to remove missing values\n",
        "print(f\"Samples: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1b2f44",
      "metadata": {
        "id": "5a1b2f44"
      },
      "source": [
        "## Quick Data Insights\n",
        "\n",
        "* **Explore Data:** This cell displays basic statistics about the delivery time and dataset.\n",
        "\n",
        "**Hints:**\n",
        "- Use `.min()`, `.max()`, `.mean()` for statistics\n",
        "- Use `.nunique()` to count unique values\n",
        "\n",
        "**Documentation:**\n",
        "- [Series.min](https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html)\n",
        "- [Series.max](https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html)\n",
        "- [Series.mean](https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html)\n",
        "- [Series.nunique](https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e815335",
      "metadata": {
        "id": "8e815335"
      },
      "outputs": [],
      "source": [
        "# Basic stats\n",
        "print(\"Delivery Time Stats:\")\n",
        "print(f\"   Min: {df['Delivery time'].______()} min\")  # Fill: method to get minimum\n",
        "print(f\"   Max: {df['Delivery time'].______()} min\")  # Fill: method to get maximum\n",
        "print(f\"   Avg: {df['Delivery time'].______():.1f} min\")  # Fill: method to get average\n",
        "\n",
        "print(f\"\\nCities: {df['City'].______()}\")  # Fill: method to count unique values\n",
        "print(f\"Areas: {df['Area'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7135991c",
      "metadata": {
        "id": "7135991c"
      },
      "source": [
        "* **City Analysis:** This cell shows the top cities by restaurant count and average delivery time.\n",
        "\n",
        "**Hints:**\n",
        "- Use `.value_counts()` to count occurrences\n",
        "\n",
        "\n",
        "**Documentation:**\n",
        "- [Series.value_counts](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93f6269",
      "metadata": {
        "id": "b93f6269"
      },
      "outputs": [],
      "source": [
        "# Top 5 cities by restaurant count\n",
        "print(\"Top 5 Cities by Restaurants:\")\n",
        "print(df['City'].______().head())  # Fill: method to count value occurrences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a64138ca",
      "metadata": {
        "id": "a64138ca"
      },
      "source": [
        "## Preprocessing and Model Training\n",
        "\n",
        "* **Encoding:** This cell selects features and applies one-hot encoding to categorical columns.\n",
        "\n",
        "**Hints:**\n",
        "- Use `pd.get_dummies()` for one-hot encoding\n",
        "- Specify the `columns` parameter to encode specific columns\n",
        "\n",
        "**Documentation:**\n",
        "- [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba0b846",
      "metadata": {
        "id": "1ba0b846"
      },
      "outputs": [],
      "source": [
        "# Select features\n",
        "X = df[['Price', 'Avg ratings', 'Total ratings', 'Area', 'City']]\n",
        "y = df[______]  # Fill: target column name as string\n",
        "\n",
        "# One-Hot Encoding using pd.get_dummies\n",
        "X_encoded = pd.______(X, columns=[______, ______])  # Fill: encoding function, two categorical columns\n",
        "\n",
        "print(f\"Features after encoding: {X_encoded.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9224d4b",
      "metadata": {
        "id": "a9224d4b"
      },
      "source": [
        "* **Train-Test Split:** This cell splits the data into training and testing sets.\n",
        "\n",
        "**Hints:**\n",
        "- Use `train_test_split()` function\n",
        "- Set `test_size=0.2` for 80-20 split\n",
        "- Set `random_state=42` for reproducibility\n",
        "\n",
        "**Documentation:**\n",
        "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e72b02",
      "metadata": {
        "id": "89e72b02"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = ______(X_encoded, y, test_size=______, random_state=42)  # Fill: split function, test size ratio\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "191b0e88",
      "metadata": {
        "id": "191b0e88"
      },
      "source": [
        "* **Train Decision Tree:** This cell creates and trains the Decision Tree Regressor model.\n",
        "\n",
        "**Hints:**\n",
        "- Create model with `max_depth=10` to prevent overfitting\n",
        "- Use `.fit()` method to train the model\n",
        "\n",
        "**Documentation:**\n",
        "- [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
        "- [DecisionTreeRegressor.fit](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.fit)\n",
        "- [DecisionTreeRegressor.predict](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407f7c21",
      "metadata": {
        "id": "407f7c21"
      },
      "outputs": [],
      "source": [
        "# Train Decision Tree\n",
        "model = ______(max_depth=______, random_state=42)  # Fill: model class, depth value\n",
        "model.______(X_train, y_train)  # Fill: method to train the model\n",
        "\n",
        "# Predict\n",
        "y_pred = model.______(X_test)  # Fill: method to make predictions\n",
        "print(\"Model trained!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c690c0b",
      "metadata": {
        "id": "3c690c0b"
      },
      "source": [
        "* **Evaluate Model:** This cell calculates and displays the model's performance metrics.\n",
        "\n",
        "**Hints:**\n",
        "- MAE (Mean Absolute Error) measures average prediction error\n",
        "- R2 Score measures how well the model explains variance (1.0 is perfect)\n",
        "\n",
        "**Documentation:**\n",
        "- [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
        "- [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72afb1df",
      "metadata": {
        "id": "72afb1df"
      },
      "outputs": [],
      "source": [
        "# Evaluate\n",
        "mae = ______(y_test, y_pred)  # Fill: function to calculate MAE\n",
        "r2 = ______(y_test, y_pred)  # Fill: function to calculate R² score\n",
        "\n",
        "print(f\"MAE: {mae:.2f} min\")\n",
        "print(f\"R²:  {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da6d640",
      "metadata": {
        "id": "4da6d640"
      },
      "source": [
        "* **Make Prediction:** This cell demonstrates how to make a prediction for a new sample.\n",
        "\n",
        "**Hints:**\n",
        "- Create a DataFrame with the same columns as training data\n",
        "- Use `.reindex()` to align columns with training data\n",
        "\n",
        "**Documentation:**\n",
        "- [DataFrame.reindex](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html)\n",
        "- [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f08615",
      "metadata": {
        "id": "e4f08615"
      },
      "outputs": [],
      "source": [
        "# Sample prediction\n",
        "sample = pd.DataFrame({\n",
        "    'Price': [400],\n",
        "    'Avg ratings': [4.2],\n",
        "    'Total ratings': [100],\n",
        "    'Area': ['Koramangala'],\n",
        "    'City': ['Bangalore']\n",
        "})\n",
        "\n",
        "# Encode sample and align columns\n",
        "sample_encoded = pd.get_dummies(sample, columns=['Area', 'City'])\n",
        "sample_encoded = sample_encoded.______(columns=X_encoded.columns, fill_value=______)  # Fill: method to align columns, default fill value\n",
        "\n",
        "prediction = model.predict(sample_encoded)[0]\n",
        "print(f\"Predicted delivery time: {prediction:.1f} min\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iK3bnEyAUUZm"
      },
      "id": "iK3bnEyAUUZm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "107ede8a"
      },
      "source": [
        "# PyTorch Neural Network - Delivery Time Prediction\n",
        "\n",
        "### Exercise: Build a Neural Network with PyTorch\n",
        "\n",
        "In this exercise, you will build a simple Neural Network using PyTorch to predict Swiggy delivery time. Fill in the blanks to complete the code."
      ],
      "id": "107ede8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "598c365e"
      },
      "source": [
        "* **Import Libraries:** This cell imports the necessary libraries including PyTorch for deep learning.\n",
        "\n",
        "**Hints:**\n",
        "- Import `torch.nn` as `nn` for neural network layers\n",
        "- Import `torch.optim` for optimizers\n",
        "- Import `DataLoader` and `TensorDataset` from torch.utils.data\n",
        "\n",
        "**Documentation:**\n",
        "- [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "- [torch.optim](https://pytorch.org/docs/stable/optim.html)\n",
        "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "- [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)"
      ],
      "id": "598c365e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aef188b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import torch\n",
        "import torch.nn as ______  # Fill: alias for neural network module\n",
        "import torch.optim as ______  # Fill: alias for optimizer module\n",
        "from torch.utils.data import ______, ______  # Fill: two classes for data loading\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "3aef188b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c6e8d02"
      },
      "source": [
        "* **Load and Prepare Data:** This cell loads the dataset and applies one-hot encoding to categorical features.\n",
        "\n",
        "**Hints:**\n",
        "- Use `.dropna()` to chain with read_csv\n",
        "- Use `pd.get_dummies()` for encoding\n",
        "\n",
        "**Documentation:**\n",
        "- [pd.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
        "- [DataFrame.dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
        "- [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
      ],
      "id": "6c6e8d02"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7971d553"
      },
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "df = pd.read_csv('swiggy.csv').______()  # Fill: method to remove missing values\n",
        "print(f\"Samples: {len(df)}\")\n",
        "\n",
        "# Select features and encode\n",
        "X = df[['Price', 'Avg ratings', 'Total ratings', 'Area', 'City']]\n",
        "y = df['Delivery time']\n",
        "\n",
        "X_encoded = pd.______(X, columns=['Area', 'City'])  # Fill: function for one-hot encoding\n",
        "print(f\"Features: {X_encoded.shape[1]}\")"
      ],
      "id": "7971d553"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cedd1e"
      },
      "source": [
        "* **Scale and Convert to Tensors:** This cell scales the features using StandardScaler and converts data to PyTorch tensors.\n",
        "\n",
        "**Hints:**\n",
        "- Use `scaler.fit_transform()` for training data\n",
        "- Use `scaler.transform()` for test data (no fitting!)\n",
        "- Use `torch.FloatTensor()` to create tensors\n",
        "\n",
        "**Documentation:**\n",
        "- [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "- [StandardScaler.fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform)\n",
        "- [torch.FloatTensor](https://pytorch.org/docs/stable/tensors.html)\n",
        "- [Tensor.reshape](https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html)"
      ],
      "id": "f8cedd1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9e0d4df"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.______(X_train)  # Fill: method to fit and transform training data\n",
        "X_test_scaled = scaler.______(X_test)  # Fill: method to transform test data (already fitted)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.______(X_train_scaled)  # Fill: tensor type for floating point\n",
        "y_train_tensor = torch.FloatTensor(y_train.values).______(______, ______)  # Fill: method to reshape, dimensions\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
        "\n",
        "print(f\"Train: {X_train_tensor.shape[0]} | Test: {X_test_tensor.shape[0]}\")"
      ],
      "id": "f9e0d4df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b898e785"
      },
      "source": [
        "## Define Neural Network\n",
        "\n",
        "* **Create Model Class:** This cell defines the neural network architecture with 2 hidden layers.\n",
        "\n",
        "**Hints:**\n",
        "- Use `nn.Linear(in_features, out_features)` for fully connected layers\n",
        "- Use `nn.ReLU()` or `nn.Sigmoid()` for activation functions\n",
        "- The network structure is: Input -> 64 neurons -> 32 neurons -> 1 output\n",
        "\n",
        "**Documentation:**\n",
        "- [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "- [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "- [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html)"
      ],
      "id": "b898e785"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bf28054"
      },
      "outputs": [],
      "source": [
        "# Simple Neural Network\n",
        "class DeliveryTimeNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(DeliveryTimeNN, self).__init__()\n",
        "        self.fc1 = nn.______(input_size, 64)  # Fill: layer type for fully connected\n",
        "        self.fc2 = nn.Linear(64, ______)  # Fill: number of neurons in second hidden layer\n",
        "        self.fc3 = nn.Linear(32, ______)  # Fill: output size for regression\n",
        "        self.activation = nn.______()  # Fill: activation function (ReLU or Sigmoid)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.______(x))  # Fill: first layer\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_tensor.shape[1]\n",
        "model = ______(input_size)  # Fill: model class name\n",
        "print(model)"
      ],
      "id": "5bf28054"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ea14b36"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "* **Training Loop:** This cell sets up the loss function, optimizer, and runs the training loop.\n",
        "\n",
        "**Hints:**\n",
        "- Use `nn.MSELoss()` for regression problems\n",
        "- Use `optim.Adam()` as the optimizer\n",
        "- Call `optimizer.zero_grad()` before each backward pass\n",
        "- Call `loss.backward()` to compute gradients\n",
        "- Call `optimizer.step()` to update weights\n",
        "\n",
        "**Documentation:**\n",
        "- [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\n",
        "- [optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)\n",
        "- [optimizer.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html)\n",
        "- [Tensor.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html)\n",
        "- [optimizer.step](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html)\n",
        "- [model.train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train)"
      ],
      "id": "8ea14b36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9877f411"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.______()  # Fill: loss function for regression (Mean Squared Error)\n",
        "optimizer = optim.______(model.parameters(), lr=0.001)  # Fill: optimizer type\n",
        "\n",
        "# Create DataLoader\n",
        "epochs = 100\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=________)  # Fill: True or False\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.______()  # Fill: mode for training\n",
        "    epoch_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.______()  # Fill: method to reset gradients\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.______()  # Fill: method to compute gradients\n",
        "        optimizer.______()  # Fill: method to update weights\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "id": "9877f411"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f5a5000"
      },
      "source": [
        "## Evaluate Model\n",
        "\n",
        "* **Test the Model:** This cell evaluates the model on the test set.\n",
        "\n",
        "**Hints:**\n",
        "- Use `model.eval()` to set evaluation mode\n",
        "- Use `torch.no_grad()` context to disable gradient computation\n",
        "- Use `.numpy()` to convert tensor to numpy array\n",
        "\n",
        "**Documentation:**\n",
        "- [model.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval)\n",
        "- [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html)\n",
        "- [Tensor.numpy](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)"
      ],
      "id": "7f5a5000"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df57d837"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "model.______()  # Fill: mode for evaluation\n",
        "with torch.______():  # Fill: context manager to disable gradients\n",
        "    y_pred = model(X_test_tensor).______()  # Fill: method to convert to numpy\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"PyTorch Neural Network Results:\")\n",
        "print(f\"   MAE: {mae:.2f} min\")\n",
        "print(f\"   R2:  {r2:.4f}\")"
      ],
      "id": "df57d837"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How these features are implemented in real swiggy and what they use to predict these kind of systems?\n",
        "\n",
        "## Here is an article how swiggy using simple embedding method implement their feature of delivery time estimation.\n",
        "https://bytes.swiggy.com/predicting-food-delivery-time-at-cart-cda23a84ba63"
      ],
      "metadata": {
        "id": "MQus0IN4Uklw"
      },
      "id": "MQus0IN4Uklw"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yn-R718QUze9"
      },
      "id": "Yn-R718QUze9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}